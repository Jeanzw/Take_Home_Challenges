{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Website Languages A/B Test\n",
    "This notebook details the approaches and the conclusions of how I approached verifying the results of an A/B Test. The test measured conversion rates when a website used custom language tamplates for spanish speaking countries compared to the same template (a Spain dialect translation) for all countries. We would think that custom templates would do better but that was not the case, the results point to the same template increasing conversions. So in this notebook I seek to see if the test can be trusted and if not what could be done differently for the next test.\n",
    "\n",
    "#### Objective\n",
    "\n",
    "1. Confirm that the test is actually negative. That is, it appears that the old version of the site with just one translation across Spain and LatAm performs better\n",
    "2. Explain why that might be happening. Are the localized translations really worse?\n",
    "3. If you identified what was wrong, design an algorithm that would return FALSE if the same problem is happening in the future and TRUE if everything is good and the results can be trusted.\n",
    "\n",
    "\n",
    "#### This notebook covers:\n",
    "\n",
    "1. Data Cleaning\n",
    "2. Verifying Results\n",
    "3. Using Statistical Tools to test for Sample Bias\n",
    "\n",
    "\n",
    "#### Conclusions:\n",
    "\n",
    "1. If the results seem unbelievable, they probably are. We intuitively know that a custom website for each region would yield better results. So when it didn't it's important to take extra precautions to make sure that the test was run appropriately, in this case we found that the test sample wasn't indicative of the population\n",
    "2. The test was misleading because suffered from sample bias and a possible small sample size which needs to be addressed.\n",
    "\n",
    "\n",
    "#### Recommendations:\n",
    "\n",
    "1. Let the test run for a longer time, the test only ran for 5 days and the results seem to be trending the in expected direction.\n",
    "2. Create a model like the decision tree used here to automate a/b test validation.\n",
    "3. Run multiple test so that we can refine the reasons why this sample might have been biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can find we always use these 4 open source package from project 1 and 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read 2 tables\n",
    "user = pd.read_csv('user_table.csv')\n",
    "test = pd.read_csv('test_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
